{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-analysis, group 3\n",
    "Our subjects: 3,5,11,17,19,25,31,33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and stuff\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics as stat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants and helper variables\n",
    "subjects = [3, 5, 11, 17, 19, 25, 31, 33]\n",
    "subjects_formatted = ['s' + str(s) for s in subjects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Sample:\n",
    "    \"\"\"Class for a sample from the data\"\"\"\n",
    "    sid: str\n",
    "    known: bool\n",
    "    xi: Optional[List[float]] = None\n",
    "    yi: Optional[List[float]] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_line(line) -> List:\n",
    "    return line.split(',')\n",
    "\n",
    "\n",
    "def parse_classes(lines) -> List[Sample]:\n",
    "    parsed_lines = [parse_line(line) for line in lines]\n",
    "    return [Sample(line[0], line[1], line[2::2], line[3::2]) for line in parsed_lines]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s5 34\n",
      "s17 23\n",
      "s19 14\n",
      "s31 33\n",
      "s3 29\n",
      "s11 10\n",
      "s25 17\n",
      "s33 33\n"
     ]
    }
   ],
   "source": [
    "# reading the lines\n",
    "with open('data/train.csv') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "    our_lines = [line for line in lines\n",
    "                 if line.split(',')[0]\n",
    "                 in subjects_formatted]\n",
    "\n",
    "    samples = parse_classes(our_lines)\n",
    "\n",
    "    sample_dict = {}\n",
    "\n",
    "    for sample in samples:\n",
    "        sample_dict.setdefault(sample.sid, []).append(sample)\n",
    "\n",
    "    for key, val in sample_dict.items():\n",
    "        print(key, len(val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fixation detection algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dispersion(x, y):\n",
    "    \"\"\"Calculate dispersion, idea from: https://github.com/ecekt/eyegaze\n",
    "\n",
    "    Args:\n",
    "        x (numpy array): x coordinates\n",
    "        y (numpy array): y coordinates\n",
    "\n",
    "    Returns:\n",
    "        float: amount of dispersion\n",
    "    \"\"\"\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return ((np.max(x.astype(float)) - np.min(x.astype(float)))\n",
    "            + (np.max(y.astype(float)) - np.min(y.astype(float))))/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idt(x, y, t, max_disp=10, min_dur=50000):\n",
    "\n",
    "    # TODO centroidin ja fiksaation pituuden palauttaminen\n",
    "\n",
    "    # helper variables\n",
    "    fixations = []\n",
    "    i = 0\n",
    "    last = 0\n",
    "\n",
    "    # loop points\n",
    "    while(i < len(x)):\n",
    "\n",
    "        # reset variables\n",
    "        dispersion = 0.0\n",
    "        window = []\n",
    "\n",
    "        # add first timepoint\n",
    "        window.append(t[last])\n",
    "\n",
    "        last_time = t[last]\n",
    "        start_time = last_time\n",
    "        last = last + 1\n",
    "\n",
    "        y_fixations = []\n",
    "        x_fixations = []\n",
    "\n",
    "        # Initialize window over first points to cover the duration threshold\n",
    "        while((start_time + min_dur) >= last_time and last + 1 < len(x)):\n",
    "            x_fixations.append(x[last])\n",
    "            y_fixations.append(y[last])\n",
    "\n",
    "            last = last + 1\n",
    "            last_time = t[last]\n",
    "\n",
    "        # If dispersion of window points <= threshold  \n",
    "        if len(x_fixations) > 0 and get_dispersion(x_fixations, y_fixations) <= max_disp:\n",
    "\n",
    "            # Add additional points to the window until dispersion > threshold  \n",
    "            while (dispersion <= max_disp and last + 1 < len(x)):\n",
    "                x_fixations.append(x[last])\n",
    "                y_fixations.append(y[last])\n",
    "\n",
    "                dispersion = get_dispersion(x_fixations, y_fixations)\n",
    "\n",
    "                last = last + 1\n",
    "                last_time = t[last]\n",
    "\n",
    "            # add window to the fixations :D\n",
    "            window.append(last_time)\n",
    "            fixations.append(window)\n",
    "\n",
    "            # Remove window points from points  \n",
    "            i = last\n",
    "        else:\n",
    "            #print(\"dispersion liikaa lol\", last, i)\n",
    "            # Remove first point from points \n",
    "            i = i + 1\n",
    "\n",
    "    # return fixation points\n",
    "    return fixations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfd(fixations):\n",
    "    # TODO\n",
    "    return sum(fixations['duration']) / len(fixations)\n",
    "\n",
    "\n",
    "def msa(fixations):\n",
    "    # TODO\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CSV-file from the analysed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\n",
    "    'subject_id',\n",
    "    'MFD_true',\n",
    "    'MFD_SD_true',\n",
    "    'MFD_false',\n",
    "    'MFD_SD_false',\n",
    "    'MSA_true',\n",
    "    'MSA_SD_true',\n",
    "    'MSA_false',\n",
    "    'MSA_SD_false',\n",
    "    'MFD_overall',\n",
    "    'MFD_overall_SD',\n",
    "    'MSA_overall',\n",
    "    'MSA_overall_SD',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kirjoitellaan csv-tiedosto\n",
    "with open(\"./results_group_3.csv\", \"w\", encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([i.lower().strip() for i in header])\n",
    "\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
